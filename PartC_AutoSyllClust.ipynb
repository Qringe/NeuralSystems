{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKqGdWBBu2DT"
   },
   "source": [
    "# Neural Systems 2021: Automated vocal segmentation project\n",
    "\n",
    "Student names: Armin Meier, Karin Zimmermann, Noah L端thi, Julian B端chel, Lukas Fluri\n",
    "\n",
    "Group: 4c\n",
    "\n",
    "## PART C: Find the best solution\n",
    "Now you are free to be creative and get the best solution for automated vocal segmentation in zebra finch songbirds.\n",
    "Some interesting neural network architectures are: cbow (linear layer + softmax function), wave-net-like (convolutional), bert, vae\n",
    "\n",
    "\n",
    "### Available training datasets:\n",
    "* g17y2: 90% of all spectrograms, 90% of all \n",
    "annotations\n",
    "* g19o10: 90% of all spectrograms, 10% of all annotations\n",
    "* g4p5: 90% of all spectrograms, 0.3% of all annotations\n",
    "* R3428: 90% of all spectrograms, 90% of all annotations (juvenile bird)\n",
    "\n",
    "Notes: \n",
    "* When only a fraction of the spectrograms are annotated, the indices of these annotated spectrograms are stored in annotations_train.SETindex_labelled.\n",
    "* Be careful that R3428 has different spectrogram parameters (e.g. annotations_train.scanrate=44100)\n",
    "\n",
    "### Constraints, filtering, and final tests performed by TA:\n",
    "**Window sizes** everyone should visit in their screening (used in final tests): 28ms, 64ms, 104ms\n",
    "\n",
    "**Recommended gap sizes** to visit: 0, 12ms, 28ms\n",
    "\n",
    "**Tests** will be run for each bird, for each variant and each of the above window sizes on the 10% of held-out test data for that bird.\n",
    "\n",
    "**An example of filtering binary labels and definition of segmentation test** performed by TAs can be found here:\n",
    "[Syllable score (by Xinyu Hao)](https://drive.google.com/file/d/10Vzqu2Z1x1jFSsKwwjOBd-8jhfe9-Q_c/view?usp=sharing)\n",
    "\n",
    "\n",
    "*Task*: Please introduce and motivate your decisions here: TODO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Segmentation (offline & online variants)\n",
    "*Task*: \n",
    "For each bird, for offline and online variants of the task, and for each of the above window sizes, please train a network that will predict segmentation on the 10% test set of that bird.\n",
    "Please store the optimal hyperparameters (including optimal gap size), optimizer choices, loss functions, and trained network parameters (using [pytorch-checkpoint](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training), or a well-documented equivalent method).\n",
    "\n",
    "**NOTE:** You first need to run all the cells at the very end of this notebook which contain the definition of the functions _task1()_ - _taskx()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6euzIniLbK9"
   },
   "source": [
    "*Task*:\n",
    "Can you improve segmentation by extending the pipeline with a filter to remove noise in binary labelling across a given time window?\n",
    "If so, please document your approach and store any parameters that you use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CiEv4l5wLash"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89NVBESQLgrq"
   },
   "source": [
    "*Task*:\n",
    "For birds g17y2 and R3428 separately, how much labelled data is needed to have good performance for an entire data set? Characterize the tradeoff between amount of annotation data and improvement in precision and recall of the binary label predictor.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QeXHGyA_LwyY"
   },
   "outputs": [],
   "source": [
    "#task3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPUW7GD-LaOz"
   },
   "source": [
    "*Task* (optional):\n",
    "Generalization across birds: How well does a segmentation network trained on a subset of the birds perform on a left-out (out-of-distribution) bird?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NpSFYwdjMFZI"
   },
   "outputs": [],
   "source": [
    "#task4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6ciYqvWMDo1"
   },
   "source": [
    "## Clustering (optional)\n",
    "To go beyond a binary classifier, you would need to find out how many vocalization / noise / silence types there are (clustering). Once you know the number of these classes, one could adjust the number of output neurons.  Some interesting approaches to define classes are: coreset, matching pursuit, kmeans.\n",
    "\n",
    "Another approach - which we have used in the past - is to extend the pipeline with more processing steps by extracting vocal segments (that can be obtained from grouping binary labels of your segmentation network) and clustering them based on their acoustic features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKoEISt_Xg9T"
   },
   "source": [
    "### Discussion\n",
    "*Task*: Discuss your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function implementations\n",
    "## Global config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tasks = {\n",
    "    \"task1\": True,\n",
    "    \"task3\": True,\n",
    "    \"task4\": True\n",
    "}\n",
    "\n",
    "# Choose between \"Local\" and \"Euler\"\n",
    "execution_mode = \"Euler\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_mode == \"Local\":\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as path\n",
    "from joblib import dump, load\n",
    "from pickle import dumps\n",
    "from hashlib import sha256\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 22}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "from utils import (\n",
    "    # Constants\n",
    "    DEVICE, BIRD_NAMES, DATA_PATH, MODEL_PATH, PREDICTIONS_PATH,\n",
    "\n",
    "    # Data handling functions\n",
    "    load_bird_data, extract_labelled_spectograms, train_test_split,\n",
    "    extract_birds, create_windows, store_birds, load_birds, store_dataset,\n",
    "    load_dataset, flatten_windows_dic, standardize_data,\n",
    "\n",
    "    # Other stuff\n",
    "    hash_spectograms, tuples2vector, score_predictions\n",
    ")\n",
    "\n",
    "from classifiers import (\n",
    "    # For the cnn\n",
    "    train_CNN, predict_syllables_CNN, load_cnn, wrap_cnn,\n",
    "\n",
    "    # For the rnn\n",
    "    train_RNN, predict_syllables_RNN, load_rnn, wrap_rnn,\n",
    "\n",
    "    # For transfer learning\n",
    "    get_transfer_learning_models_CNN, get_transfer_learning_models_RNN\n",
    ")\n",
    "\n",
    "from analyze_errors import compare_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_object(obj, ndigits = 6):\n",
    "    return sha256(dumps(obj)).hexdigest()[-ndigits:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on bird:  g17y2\n",
      "Start training for  task1_cnn_g17y2_wnd_7_online_False_size_83860\n",
      "Epoch 0 Loss 0.8758534789085388\n",
      "Epoch 0 Loss 0.10216869413852692\n",
      "Epoch 0 Loss 0.04738926887512207\n",
      "Epoch 0 Loss 0.01811426877975464\n",
      "Epoch 0 Loss 0.025233330205082893\n",
      "Epoch 0 Loss 0.03410729765892029\n",
      "Epoch 0 Loss 0.028280863538384438\n",
      "Epoch 0 Loss 0.058609772473573685\n",
      "Epoch 0 Loss 0.041971515864133835\n",
      "Epoch 0 Loss 0.013261520303785801\n",
      "Epoch 0 Loss 0.05326526239514351\n",
      "Epoch 0 Loss 0.007477572653442621\n",
      "Epoch 0 Loss 0.001621464267373085\n",
      "Epoch 0 Loss 0.012993020005524158\n",
      "Validation accuracy is 0.9915776252746582\n",
      "Epoch 1 Loss 0.05435548350214958\n",
      "Epoch 1 Loss 0.05636949464678764\n",
      "Epoch 1 Loss 0.015324054285883904\n",
      "Epoch 1 Loss 0.03689894825220108\n",
      "Epoch 1 Loss 0.006984598934650421\n",
      "Epoch 1 Loss 0.004142921883612871\n",
      "Epoch 1 Loss 0.0028567558620125055\n",
      "Epoch 1 Loss 0.019668709486722946\n",
      "Epoch 1 Loss 0.0028895498253405094\n",
      "Epoch 1 Loss 0.0577983632683754\n",
      "Epoch 1 Loss 0.02582918107509613\n",
      "Epoch 1 Loss 0.0632111057639122\n",
      "Epoch 1 Loss 0.014712881296873093\n",
      "Epoch 1 Loss 0.0006121539045125246\n",
      "Validation accuracy is 0.9928814172744751\n",
      "Epoch 2 Loss 0.03067355789244175\n",
      "Epoch 2 Loss 0.008317027240991592\n",
      "Epoch 2 Loss 0.0004336909914854914\n",
      "Epoch 2 Loss 0.005252568516880274\n",
      "Epoch 2 Loss 0.0071887304075062275\n",
      "Epoch 2 Loss 0.02455146238207817\n",
      "Epoch 2 Loss 0.014193058013916016\n",
      "Epoch 2 Loss 0.018014194443821907\n",
      "Epoch 2 Loss 0.002323069842532277\n",
      "Epoch 2 Loss 0.004567006137222052\n",
      "Epoch 2 Loss 0.03330798074603081\n",
      "Epoch 2 Loss 0.0009283354738727212\n",
      "Epoch 2 Loss 0.027413927018642426\n",
      "Epoch 2 Loss 0.004169829655438662\n",
      "Validation accuracy is 0.9909331798553467\n",
      "Epoch 3 Loss 0.02017311006784439\n",
      "Epoch 3 Loss 0.006929959636181593\n",
      "Epoch 3 Loss 0.009267088025808334\n",
      "Epoch 3 Loss 0.025573762133717537\n",
      "Epoch 3 Loss 0.006537490990012884\n",
      "Epoch 3 Loss 0.08261366188526154\n",
      "Epoch 3 Loss 0.00031285209115594625\n",
      "Epoch 3 Loss 0.0009611261775717139\n",
      "Epoch 3 Loss 0.001395443337969482\n",
      "Epoch 3 Loss 0.06143566966056824\n",
      "Epoch 3 Loss 0.002476335968822241\n",
      "Epoch 3 Loss 0.01711474359035492\n",
      "Epoch 3 Loss 0.018682654947042465\n",
      "Epoch 3 Loss 0.000405495404265821\n",
      "Validation accuracy is 0.9917424917221069\n",
      "Epoch 4 Loss 0.023254018276929855\n",
      "Epoch 4 Loss 0.0021885535679757595\n",
      "Epoch 4 Loss 0.014325232245028019\n",
      "Epoch 4 Loss 0.012556230649352074\n",
      "Epoch 4 Loss 0.003926859237253666\n",
      "Epoch 4 Loss 0.0009465333423577249\n",
      "Epoch 4 Loss 0.008225579746067524\n",
      "Epoch 4 Loss 0.0064346217550337315\n",
      "Epoch 4 Loss 0.0037970442790538073\n",
      "Epoch 4 Loss 0.0010461540659889579\n",
      "Epoch 4 Loss 0.015785090625286102\n",
      "Epoch 4 Loss 0.002964770421385765\n",
      "Epoch 4 Loss 0.052442628890275955\n",
      "Epoch 4 Loss 0.004831550642848015\n",
      "Validation accuracy is 0.9941552877426147\n",
      "Epoch 5 Loss 0.0003119360189884901\n",
      "Epoch 5 Loss 0.0020912024192512035\n",
      "Epoch 5 Loss 0.000611522642429918\n",
      "Epoch 5 Loss 0.013378127478063107\n",
      "Epoch 5 Loss 0.008327653631567955\n",
      "Epoch 5 Loss 0.0030233156867325306\n",
      "Epoch 5 Loss 0.013371005654335022\n",
      "Epoch 5 Loss 0.000354908115696162\n",
      "Epoch 5 Loss 0.00018511999223846942\n",
      "Epoch 5 Loss 0.008436216972768307\n",
      "Epoch 5 Loss 0.00017497947555966675\n",
      "Epoch 5 Loss 0.00027882176800630987\n",
      "Epoch 5 Loss 0.0009850867791101336\n",
      "Epoch 5 Loss 0.002547315089032054\n",
      "Validation accuracy is 0.993450939655304\n",
      "Epoch 6 Loss 0.0016480316407978535\n",
      "Epoch 6 Loss 0.05298888310790062\n",
      "Epoch 6 Loss 0.0014039387460798025\n",
      "Epoch 6 Loss 0.00703512504696846\n",
      "Epoch 6 Loss 0.05178876966238022\n",
      "Epoch 6 Loss 0.0016097306506708264\n",
      "Epoch 6 Loss 0.006988404784351587\n",
      "Epoch 6 Loss 0.004731589928269386\n",
      "Epoch 6 Loss 0.008778606541454792\n",
      "Epoch 6 Loss 0.0003966092481277883\n",
      "Epoch 6 Loss 0.0018687675474211574\n",
      "Epoch 6 Loss 0.00021717333584092557\n",
      "Epoch 6 Loss 0.013923302292823792\n",
      "Epoch 6 Loss 2.0749663235619664e-05\n",
      "Validation accuracy is 0.9943950772285461\n",
      "Epoch 7 Loss 0.02316502295434475\n",
      "Epoch 7 Loss 0.00019385720952413976\n",
      "Epoch 7 Loss 0.04603523388504982\n",
      "Epoch 7 Loss 0.0014072988415136933\n",
      "Epoch 7 Loss 0.03305462375283241\n",
      "Epoch 7 Loss 5.245432475931011e-05\n",
      "Epoch 7 Loss 0.012044600211083889\n",
      "Epoch 7 Loss 0.00025292017380706966\n",
      "Epoch 7 Loss 0.005602396093308926\n",
      "Epoch 7 Loss 0.00962307583540678\n",
      "Epoch 7 Loss 0.001919300528243184\n",
      "Epoch 7 Loss 0.002431105123832822\n",
      "Epoch 7 Loss 0.0014553372748196125\n",
      "Epoch 7 Loss 0.008620610460639\n",
      "Validation accuracy is 0.9944400191307068\n",
      "Epoch 8 Loss 0.008256261236965656\n",
      "Epoch 8 Loss 0.005281655117869377\n",
      "Epoch 8 Loss 0.02016468718647957\n",
      "Epoch 8 Loss 5.7397242926526815e-05\n",
      "Epoch 8 Loss 0.000931551621761173\n",
      "Epoch 8 Loss 9.09317604964599e-05\n",
      "Epoch 8 Loss 0.0002412953763268888\n",
      "Epoch 8 Loss 0.0028906152583658695\n",
      "Epoch 8 Loss 0.00047061717486940324\n",
      "Epoch 8 Loss 0.0003145649970974773\n",
      "Epoch 8 Loss 0.0003321555268485099\n",
      "Epoch 8 Loss 0.05791575089097023\n",
      "Epoch 8 Loss 0.00025772108347155154\n",
      "Epoch 8 Loss 0.010585932992398739\n",
      "Validation accuracy is 0.9947397708892822\n",
      "Epoch 9 Loss 0.014360843226313591\n",
      "Epoch 9 Loss 0.04949159175157547\n",
      "Epoch 9 Loss 0.00607679970562458\n",
      "Epoch 9 Loss 0.0030838046222925186\n",
      "Epoch 9 Loss 9.389949991600588e-05\n",
      "Epoch 9 Loss 0.003132101148366928\n",
      "Epoch 9 Loss 0.001210722140967846\n",
      "Epoch 9 Loss 0.0002613085962366313\n",
      "Epoch 9 Loss 0.00019356906705070287\n",
      "Epoch 9 Loss 0.0265178419649601\n",
      "Epoch 9 Loss 0.00038540453533641994\n",
      "Epoch 9 Loss 0.0030984366312623024\n",
      "Epoch 9 Loss 0.0020048548467457294\n",
      "Epoch 9 Loss 0.004138604737818241\n",
      "Validation accuracy is 0.994904637336731\n",
      "Test acc. 0.9953873157501221\n",
      "Start training for  task1_cnn_g17y2_wnd_7_online_True_size_84333\n",
      "Epoch 0 Loss 0.7318535447120667\n",
      "Epoch 0 Loss 0.14877447485923767\n",
      "Epoch 0 Loss 0.16226990520954132\n",
      "Epoch 0 Loss 0.061905305832624435\n",
      "Epoch 0 Loss 0.13874846696853638\n",
      "Epoch 0 Loss 0.2199534922838211\n",
      "Epoch 0 Loss 0.09877883642911911\n",
      "Epoch 0 Loss 0.10172129422426224\n",
      "Epoch 0 Loss 0.08232763409614563\n",
      "Epoch 0 Loss 0.049389880150556564\n",
      "Epoch 0 Loss 0.08983562886714935\n",
      "Epoch 0 Loss 0.1488139033317566\n",
      "Epoch 0 Loss 0.01353857945650816\n",
      "Epoch 0 Loss 0.01910797506570816\n",
      "Validation accuracy is 0.9783616065979004\n",
      "Epoch 1 Loss 0.01290938351303339\n",
      "Epoch 1 Loss 0.09364242851734161\n",
      "Epoch 1 Loss 0.021464301273226738\n",
      "Epoch 1 Loss 0.012786533683538437\n",
      "Epoch 1 Loss 0.11570703238248825\n",
      "Epoch 1 Loss 0.16724231839179993\n",
      "Epoch 1 Loss 0.039715226739645004\n",
      "Epoch 1 Loss 0.1210600733757019\n",
      "Epoch 1 Loss 0.012954436242580414\n",
      "Epoch 1 Loss 0.02221744693815708\n",
      "Epoch 1 Loss 0.1718849241733551\n",
      "Epoch 1 Loss 0.0778636559844017\n",
      "Epoch 1 Loss 0.16283047199249268\n",
      "Epoch 1 Loss 0.09332701563835144\n",
      "Validation accuracy is 0.9833539724349976\n",
      "Epoch 2 Loss 0.1031905934214592\n",
      "Epoch 2 Loss 0.09003707766532898\n",
      "Epoch 2 Loss 0.027043625712394714\n",
      "Epoch 2 Loss 0.024877220392227173\n",
      "Epoch 2 Loss 0.059172745794057846\n",
      "Epoch 2 Loss 0.016605675220489502\n",
      "Epoch 2 Loss 0.041784677654504776\n",
      "Epoch 2 Loss 0.007837945595383644\n",
      "Epoch 2 Loss 0.006227034609764814\n",
      "Epoch 2 Loss 0.08163052797317505\n",
      "Epoch 2 Loss 0.055932193994522095\n",
      "Epoch 2 Loss 0.08379486203193665\n",
      "Epoch 2 Loss 0.0786576047539711\n",
      "Epoch 2 Loss 0.008269006386399269\n",
      "Validation accuracy is 0.9827727675437927\n",
      "Epoch 3 Loss 0.10724460333585739\n",
      "Epoch 3 Loss 0.1248556524515152\n",
      "Epoch 3 Loss 0.06551229953765869\n",
      "Epoch 3 Loss 0.10738515108823776\n",
      "Epoch 3 Loss 0.27773618698120117\n",
      "Epoch 3 Loss 0.0074433996342122555\n",
      "Epoch 3 Loss 0.016136078163981438\n",
      "Epoch 3 Loss 0.09125177562236786\n",
      "Epoch 3 Loss 0.04909805580973625\n",
      "Epoch 3 Loss 0.01894897036254406\n",
      "Epoch 3 Loss 0.26916709542274475\n",
      "Epoch 3 Loss 0.0708785280585289\n",
      "Epoch 3 Loss 0.01777692139148712\n",
      "Epoch 3 Loss 0.0689346194267273\n",
      "Validation accuracy is 0.9862152338027954\n",
      "Epoch 4 Loss 0.061799418181180954\n",
      "Epoch 4 Loss 0.025658007711172104\n",
      "Epoch 4 Loss 0.01782105304300785\n",
      "Epoch 4 Loss 0.008432695642113686\n",
      "Epoch 4 Loss 0.010768135078251362\n",
      "Epoch 4 Loss 0.014731699600815773\n",
      "Epoch 4 Loss 0.088678278028965\n",
      "Epoch 4 Loss 0.07099689543247223\n",
      "Epoch 4 Loss 0.17996330559253693\n",
      "Epoch 4 Loss 0.09766653180122375\n",
      "Epoch 4 Loss 0.01064970437437296\n",
      "Epoch 4 Loss 0.02090962789952755\n",
      "Epoch 4 Loss 0.055012091994285583\n",
      "Epoch 4 Loss 0.007526580709964037\n",
      "Validation accuracy is 0.985499918460846\n",
      "Epoch 5 Loss 0.015765678137540817\n",
      "Epoch 5 Loss 0.014405319467186928\n",
      "Epoch 5 Loss 0.05418453738093376\n",
      "Epoch 5 Loss 0.08116532117128372\n",
      "Epoch 5 Loss 0.012823106721043587\n",
      "Epoch 5 Loss 0.02022426575422287\n",
      "Epoch 5 Loss 0.03336431458592415\n",
      "Epoch 5 Loss 0.027556732296943665\n",
      "Epoch 5 Loss 0.039605457335710526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss 0.1543959528207779\n",
      "Epoch 5 Loss 0.03060126304626465\n",
      "Epoch 5 Loss 0.04241035506129265\n",
      "Epoch 5 Loss 0.016767216846346855\n",
      "Epoch 5 Loss 0.0066005764529109\n",
      "Validation accuracy is 0.9855595231056213\n",
      "Epoch 6 Loss 0.04996636509895325\n",
      "Epoch 6 Loss 0.07615514099597931\n",
      "Epoch 6 Loss 0.0046300156973302364\n",
      "Epoch 6 Loss 0.05202946066856384\n",
      "Epoch 6 Loss 0.022672204300761223\n",
      "Epoch 6 Loss 0.011503955349326134\n",
      "Epoch 6 Loss 0.064595527946949\n",
      "Epoch 6 Loss 0.008880970999598503\n",
      "Epoch 6 Loss 0.009030409157276154\n",
      "Epoch 6 Loss 0.011943376623094082\n",
      "Epoch 6 Loss 0.02366451546549797\n",
      "Epoch 6 Loss 0.007193665951490402\n",
      "Epoch 6 Loss 0.028303833678364754\n",
      "Epoch 6 Loss 0.00798269547522068\n",
      "Validation accuracy is 0.9866771697998047\n",
      "Epoch 7 Loss 0.011838548816740513\n",
      "Epoch 7 Loss 0.02042078971862793\n",
      "Epoch 7 Loss 0.06027081981301308\n",
      "Epoch 7 Loss 0.0036901412531733513\n",
      "Epoch 7 Loss 0.06329280138015747\n",
      "Epoch 7 Loss 0.007767015136778355\n",
      "Epoch 7 Loss 0.06022808700799942\n",
      "Epoch 7 Loss 0.008129320107400417\n",
      "Epoch 7 Loss 0.005512496456503868\n",
      "Epoch 7 Loss 0.0039263213984668255\n",
      "Epoch 7 Loss 0.02221069298684597\n",
      "Epoch 7 Loss 0.009578358381986618\n",
      "Epoch 7 Loss 0.010778229683637619\n",
      "Epoch 7 Loss 0.0032218077685683966\n",
      "Validation accuracy is 0.9868858456611633\n",
      "Epoch 8 Loss 0.009687714278697968\n",
      "Epoch 8 Loss 0.05848541483283043\n",
      "Epoch 8 Loss 0.0028290492482483387\n",
      "Epoch 8 Loss 0.08564145863056183\n",
      "Epoch 8 Loss 0.01899493858218193\n",
      "Epoch 8 Loss 0.008211588487029076\n",
      "Epoch 8 Loss 0.013898765668272972\n",
      "Epoch 8 Loss 0.07808497548103333\n",
      "Epoch 8 Loss 0.10223793983459473\n",
      "Epoch 8 Loss 0.06587355583906174\n",
      "Epoch 8 Loss 0.0029624460730701685\n",
      "Epoch 8 Loss 0.007092643994837999\n",
      "Epoch 8 Loss 0.09142347425222397\n",
      "Epoch 8 Loss 0.02978621982038021\n",
      "Validation accuracy is 0.9869454503059387\n",
      "Epoch 9 Loss 0.01153569109737873\n",
      "Epoch 9 Loss 0.06504137068986893\n",
      "Epoch 9 Loss 0.012430482544004917\n",
      "Epoch 9 Loss 0.0119290417060256\n",
      "Epoch 9 Loss 0.011803096160292625\n",
      "Epoch 9 Loss 0.006973272655159235\n",
      "Epoch 9 Loss 0.012525955215096474\n",
      "Epoch 9 Loss 0.014512458816170692\n",
      "Epoch 9 Loss 0.09535051137208939\n",
      "Epoch 9 Loss 0.004373261239379644\n",
      "Epoch 9 Loss 0.005083057098090649\n",
      "Epoch 9 Loss 0.04136122763156891\n",
      "Epoch 9 Loss 0.015761854127049446\n",
      "Epoch 9 Loss 0.1377246081829071\n",
      "Validation accuracy is 0.9872285723686218\n",
      "Test acc. 0.9878883361816406\n",
      "Start training for  task1_cnn_g17y2_wnd_16_online_False_size_82666\n",
      "Epoch 0 Loss 0.9680079817771912\n",
      "Epoch 0 Loss 0.07782138884067535\n",
      "Epoch 0 Loss 0.07326658815145493\n",
      "Epoch 0 Loss 0.06326351314783096\n",
      "Epoch 0 Loss 0.0025387899950146675\n",
      "Epoch 0 Loss 0.014676693826913834\n",
      "Epoch 0 Loss 0.01859627477824688\n",
      "Epoch 0 Loss 0.04432026669383049\n",
      "Epoch 0 Loss 0.018934903666377068\n",
      "Epoch 0 Loss 0.06582832336425781\n",
      "Epoch 0 Loss 0.009086232632398605\n",
      "Epoch 0 Loss 0.009104928001761436\n",
      "Epoch 0 Loss 0.0034177026245743036\n",
      "Validation accuracy is 0.9928529262542725\n",
      "Epoch 1 Loss 0.04649613797664642\n",
      "Epoch 1 Loss 0.031368598341941833\n",
      "Epoch 1 Loss 0.01060082484036684\n",
      "Epoch 1 Loss 0.06326441466808319\n",
      "Epoch 1 Loss 0.0034816297702491283\n",
      "Epoch 1 Loss 0.05686226487159729\n",
      "Epoch 1 Loss 0.002441929653286934\n",
      "Epoch 1 Loss 0.00460969191044569\n",
      "Epoch 1 Loss 0.016558652743697166\n",
      "Epoch 1 Loss 0.014269598759710789\n",
      "Epoch 1 Loss 0.00014370687131304294\n",
      "Epoch 1 Loss 0.013674270361661911\n",
      "Epoch 1 Loss 0.017868515104055405\n",
      "Validation accuracy is 0.9932026863098145\n",
      "Epoch 2 Loss 0.004136145580559969\n",
      "Epoch 2 Loss 0.0026314910501241684\n",
      "Epoch 2 Loss 0.005093807354569435\n",
      "Epoch 2 Loss 0.020777830854058266\n",
      "Epoch 2 Loss 0.06512746214866638\n",
      "Epoch 2 Loss 0.0036349445581436157\n",
      "Epoch 2 Loss 0.00197161384858191\n",
      "Epoch 2 Loss 0.026836127042770386\n",
      "Epoch 2 Loss 0.006360592786222696\n",
      "Epoch 2 Loss 0.00011752843420254067\n",
      "Epoch 2 Loss 0.018740737810730934\n",
      "Epoch 2 Loss 0.002509558107703924\n",
      "Epoch 2 Loss 0.011278986930847168\n",
      "Validation accuracy is 0.993324339389801\n",
      "Epoch 3 Loss 0.018851669505238533\n",
      "Epoch 3 Loss 0.0014802367659285665\n",
      "Epoch 3 Loss 0.0007674603257328272\n",
      "Epoch 3 Loss 0.0047263395972549915\n",
      "Epoch 3 Loss 0.00436572078615427\n",
      "Epoch 3 Loss 0.007247928064316511\n",
      "Epoch 3 Loss 0.0001431899145245552\n",
      "Epoch 3 Loss 0.002897885162383318\n",
      "Epoch 3 Loss 0.0034976310562342405\n",
      "Epoch 3 Loss 0.0002801640657708049\n",
      "Epoch 3 Loss 0.0023787724785506725\n",
      "Epoch 3 Loss 0.002397945150732994\n",
      "Epoch 3 Loss 0.00010995860066032037\n",
      "Validation accuracy is 0.9940694570541382\n",
      "Epoch 4 Loss 0.013403134420514107\n",
      "Epoch 4 Loss 0.048560429364442825\n",
      "Epoch 4 Loss 0.004127738066017628\n",
      "Epoch 4 Loss 4.3684616684913635e-05\n",
      "Epoch 4 Loss 0.0003041933523491025\n",
      "Epoch 4 Loss 0.0011960569536313415\n",
      "Epoch 4 Loss 0.013126933947205544\n",
      "Epoch 4 Loss 0.0017709893872961402\n",
      "Epoch 4 Loss 0.005122298374772072\n",
      "Epoch 4 Loss 0.02204160951077938\n",
      "Epoch 4 Loss 0.031972676515579224\n",
      "Epoch 4 Loss 0.0018148869276046753\n",
      "Epoch 4 Loss 0.001978431362658739\n",
      "Validation accuracy is 0.9938717484474182\n",
      "Epoch 5 Loss 0.017240317538380623\n",
      "Epoch 5 Loss 0.0008193050161935389\n",
      "Epoch 5 Loss 0.0004703917365986854\n",
      "Epoch 5 Loss 0.00029810392879880965\n",
      "Epoch 5 Loss 2.381029298703652e-05\n",
      "Epoch 5 Loss 0.007401584181934595\n",
      "Epoch 5 Loss 0.0004173675552010536\n",
      "Epoch 5 Loss 0.00038371371920220554\n",
      "Epoch 5 Loss 0.0004959884681738913\n",
      "Epoch 5 Loss 0.010114253498613834\n",
      "Epoch 5 Loss 0.0433250330388546\n",
      "Epoch 5 Loss 0.015343566425144672\n",
      "Epoch 5 Loss 0.0008885361021384597\n",
      "Validation accuracy is 0.9942215085029602\n",
      "Epoch 6 Loss 0.005948815029114485\n",
      "Epoch 6 Loss 0.022360537201166153\n",
      "Epoch 6 Loss 3.0423525458900258e-05\n",
      "Epoch 6 Loss 0.0016670702025294304\n",
      "Epoch 6 Loss 0.010387437418103218\n",
      "Epoch 6 Loss 0.004260471556335688\n",
      "Epoch 6 Loss 0.0050673699006438255\n",
      "Epoch 6 Loss 0.013709421269595623\n",
      "Epoch 6 Loss 1.244239342668152e-06\n",
      "Epoch 6 Loss 0.0006174258887767792\n",
      "Epoch 6 Loss 1.5708821592852473e-05\n",
      "Epoch 6 Loss 8.489942410960793e-05\n",
      "Epoch 6 Loss 0.006831103935837746\n",
      "Validation accuracy is 0.9943583607673645\n",
      "Epoch 7 Loss 0.0024837087839841843\n",
      "Epoch 7 Loss 0.0012301498791202903\n",
      "Epoch 7 Loss 0.0016042114002630115\n",
      "Epoch 7 Loss 3.576458038878627e-05\n",
      "Epoch 7 Loss 0.0011915352661162615\n",
      "Epoch 7 Loss 1.9203034753445536e-05\n",
      "Epoch 7 Loss 0.0038982797414064407\n",
      "Epoch 7 Loss 0.006417147349566221\n",
      "Epoch 7 Loss 0.0008917090017348528\n",
      "Epoch 7 Loss 0.0029613913502544165\n",
      "Epoch 7 Loss 8.992466609925032e-05\n",
      "Epoch 7 Loss 9.180141933029518e-05\n",
      "Epoch 7 Loss 0.004138557706028223\n",
      "Validation accuracy is 0.9935676455497742\n",
      "Epoch 8 Loss 0.02795177511870861\n",
      "Epoch 8 Loss 5.9396355936769396e-05\n",
      "Epoch 8 Loss 0.0002605526533443481\n",
      "Epoch 8 Loss 0.0004966483684256673\n",
      "Epoch 8 Loss 0.0006454741233028471\n",
      "Epoch 8 Loss 0.00019384975894354284\n",
      "Epoch 8 Loss 0.00026394595624879\n",
      "Epoch 8 Loss 0.0009128075907938182\n",
      "Epoch 8 Loss 0.0005388165009208024\n",
      "Epoch 8 Loss 0.02398054674267769\n",
      "Epoch 8 Loss 7.937428563309368e-06\n",
      "Epoch 8 Loss 0.01802290976047516\n",
      "Epoch 8 Loss 0.012027354910969734\n",
      "Validation accuracy is 0.9937804937362671\n",
      "Epoch 9 Loss 0.019256411120295525\n",
      "Epoch 9 Loss 0.0005653556436300278\n",
      "Epoch 9 Loss 0.004924073815345764\n",
      "Epoch 9 Loss 0.0003506596840452403\n",
      "Epoch 9 Loss 0.0003672683669719845\n",
      "Epoch 9 Loss 0.009110203944146633\n",
      "Epoch 9 Loss 0.0006732109468430281\n",
      "Epoch 9 Loss 0.025455044582486153\n",
      "Epoch 9 Loss 1.1633048416115344e-05\n",
      "Epoch 9 Loss 0.0001662922732066363\n",
      "Epoch 9 Loss 0.0338696651160717\n",
      "Epoch 9 Loss 3.725277224475576e-07\n",
      "Epoch 9 Loss 0.00021768234728369862\n",
      "Validation accuracy is 0.9928681254386902\n",
      "Test acc. 0.9940714836120605\n",
      "Start training for  task1_cnn_g17y2_wnd_16_online_True_size_83736\n",
      "Epoch 0 Loss 0.7906451225280762\n",
      "Epoch 0 Loss 0.18989329040050507\n",
      "Epoch 0 Loss 0.1994740068912506\n",
      "Epoch 0 Loss 0.10328080505132675\n",
      "Epoch 0 Loss 0.12460498511791229\n",
      "Epoch 0 Loss 0.05271154269576073\n",
      "Epoch 0 Loss 0.12096890062093735\n",
      "Epoch 0 Loss 0.07008717954158783\n",
      "Epoch 0 Loss 0.2841491103172302\n",
      "Epoch 0 Loss 0.0728035494685173\n",
      "Epoch 0 Loss 0.036671534180641174\n",
      "Epoch 0 Loss 0.006446524523198605\n",
      "Epoch 0 Loss 0.0902998298406601\n",
      "Epoch 0 Loss 0.09540998935699463\n",
      "Validation accuracy is 0.9696487784385681\n",
      "Epoch 1 Loss 0.2285429686307907\n",
      "Epoch 1 Loss 0.02870727889239788\n",
      "Epoch 1 Loss 0.01246632169932127\n",
      "Epoch 1 Loss 0.07122906297445297\n",
      "Epoch 1 Loss 0.07040820270776749\n",
      "Epoch 1 Loss 0.049493495374917984\n",
      "Epoch 1 Loss 0.027761824429035187\n",
      "Epoch 1 Loss 0.059509456157684326\n",
      "Epoch 1 Loss 0.071031354367733\n",
      "Epoch 1 Loss 0.014024334959685802\n",
      "Epoch 1 Loss 0.08035306632518768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.043284788727760315\n",
      "Epoch 1 Loss 0.03868089243769646\n",
      "Epoch 1 Loss 0.13769392669200897\n",
      "Validation accuracy is 0.9823476672172546\n",
      "Epoch 2 Loss 0.06372535228729248\n",
      "Epoch 2 Loss 0.03163696452975273\n",
      "Epoch 2 Loss 0.02683958411216736\n",
      "Epoch 2 Loss 0.026177367195487022\n",
      "Epoch 2 Loss 0.09479530155658722\n",
      "Epoch 2 Loss 0.0565023235976696\n",
      "Epoch 2 Loss 0.009569858200848103\n",
      "Epoch 2 Loss 0.023640142753720284\n",
      "Epoch 2 Loss 0.07190632075071335\n",
      "Epoch 2 Loss 0.10717109590768814\n",
      "Epoch 2 Loss 0.003959172870963812\n",
      "Epoch 2 Loss 0.007356366142630577\n",
      "Epoch 2 Loss 0.0827811062335968\n",
      "Epoch 2 Loss 0.11938020586967468\n",
      "Validation accuracy is 0.9823776483535767\n",
      "Epoch 3 Loss 0.11551572382450104\n",
      "Epoch 3 Loss 0.052322812378406525\n",
      "Epoch 3 Loss 0.009869316592812538\n",
      "Epoch 3 Loss 0.07923756539821625\n",
      "Epoch 3 Loss 0.011085119098424911\n",
      "Epoch 3 Loss 0.19074974954128265\n",
      "Epoch 3 Loss 0.007683540228754282\n",
      "Epoch 3 Loss 0.005629412829875946\n",
      "Epoch 3 Loss 0.15599283576011658\n",
      "Epoch 3 Loss 0.06907057017087936\n",
      "Epoch 3 Loss 0.06956380605697632\n",
      "Epoch 3 Loss 0.05783938989043236\n",
      "Epoch 3 Loss 0.08560377359390259\n",
      "Epoch 3 Loss 0.006469231564551592\n",
      "Validation accuracy is 0.9837136268615723\n",
      "Epoch 4 Loss 0.044936809688806534\n",
      "Epoch 4 Loss 0.0051065185107290745\n",
      "Epoch 4 Loss 0.06034580245614052\n",
      "Epoch 4 Loss 0.06837175041437149\n",
      "Epoch 4 Loss 0.13922415673732758\n",
      "Epoch 4 Loss 0.01935231126844883\n",
      "Epoch 4 Loss 0.09944921731948853\n",
      "Epoch 4 Loss 0.13844925165176392\n",
      "Epoch 4 Loss 0.021593168377876282\n",
      "Epoch 4 Loss 0.021170128136873245\n",
      "Epoch 4 Loss 0.10092680156230927\n",
      "Epoch 4 Loss 0.041513342410326004\n",
      "Epoch 4 Loss 0.005851356778293848\n",
      "Epoch 4 Loss 0.08417236804962158\n",
      "Validation accuracy is 0.984734296798706\n",
      "Epoch 5 Loss 0.12047465145587921\n",
      "Epoch 5 Loss 0.004517512395977974\n",
      "Epoch 5 Loss 0.011272691190242767\n",
      "Epoch 5 Loss 0.014501241967082024\n",
      "Epoch 5 Loss 0.04959702491760254\n",
      "Epoch 5 Loss 0.08680138736963272\n",
      "Epoch 5 Loss 0.03310559689998627\n",
      "Epoch 5 Loss 0.04664280265569687\n",
      "Epoch 5 Loss 0.004354405216872692\n",
      "Epoch 5 Loss 0.03314155712723732\n",
      "Epoch 5 Loss 0.04927585646510124\n",
      "Epoch 5 Loss 0.042755331844091415\n",
      "Epoch 5 Loss 0.09799179434776306\n",
      "Epoch 5 Loss 0.014612809754908085\n",
      "Validation accuracy is 0.9846142530441284\n",
      "Epoch 6 Loss 0.001509299618192017\n",
      "Epoch 6 Loss 0.014241467230021954\n",
      "Epoch 6 Loss 0.05550535023212433\n",
      "Epoch 6 Loss 0.099701426923275\n",
      "Epoch 6 Loss 0.005333753768354654\n",
      "Epoch 6 Loss 0.0369151309132576\n",
      "Epoch 6 Loss 0.01605299860239029\n",
      "Epoch 6 Loss 0.003058555768802762\n",
      "Epoch 6 Loss 0.10641364753246307\n",
      "Epoch 6 Loss 0.008720866404473782\n",
      "Epoch 6 Loss 0.01773572899401188\n",
      "Epoch 6 Loss 0.010728335939347744\n",
      "Epoch 6 Loss 0.06651580333709717\n",
      "Epoch 6 Loss 0.013723759911954403\n",
      "Validation accuracy is 0.985424816608429\n",
      "Epoch 7 Loss 0.021747203543782234\n",
      "Epoch 7 Loss 0.013426648452877998\n",
      "Epoch 7 Loss 0.10148286074399948\n",
      "Epoch 7 Loss 0.005525466986000538\n",
      "Epoch 7 Loss 0.10524026304483414\n",
      "Epoch 7 Loss 0.0045422883704304695\n",
      "Epoch 7 Loss 0.07058508694171906\n",
      "Epoch 7 Loss 0.005672157276421785\n",
      "Epoch 7 Loss 0.04005628079175949\n",
      "Epoch 7 Loss 0.0023861960507929325\n",
      "Epoch 7 Loss 0.048713814467191696\n",
      "Epoch 7 Loss 0.008927731774747372\n",
      "Epoch 7 Loss 0.1744481772184372\n",
      "Epoch 7 Loss 0.010400824248790741\n",
      "Validation accuracy is 0.9863554239273071\n",
      "Epoch 8 Loss 0.005418806336820126\n",
      "Epoch 8 Loss 0.06495578587055206\n",
      "Epoch 8 Loss 0.002872892189770937\n",
      "Epoch 8 Loss 0.004046318121254444\n",
      "Epoch 8 Loss 0.00350659410469234\n",
      "Epoch 8 Loss 0.0846896842122078\n",
      "Epoch 8 Loss 0.009505504742264748\n",
      "Epoch 8 Loss 0.10580649971961975\n",
      "Epoch 8 Loss 0.11904037743806839\n",
      "Epoch 8 Loss 0.016382776200771332\n",
      "Epoch 8 Loss 0.033727891743183136\n",
      "Epoch 8 Loss 0.010599816218018532\n",
      "Epoch 8 Loss 0.07966741174459457\n",
      "Epoch 8 Loss 0.05720314756035805\n",
      "Validation accuracy is 0.9829480648040771\n",
      "Epoch 9 Loss 0.031504131853580475\n",
      "Epoch 9 Loss 0.008965055458247662\n",
      "Epoch 9 Loss 0.006381337530910969\n",
      "Epoch 9 Loss 0.01705382950603962\n",
      "Epoch 9 Loss 0.01966005191206932\n",
      "Epoch 9 Loss 0.0016353793907910585\n",
      "Epoch 9 Loss 0.028571926057338715\n",
      "Epoch 9 Loss 0.008446688763797283\n",
      "Epoch 9 Loss 0.003639844711869955\n",
      "Epoch 9 Loss 0.013684837147593498\n",
      "Epoch 9 Loss 0.012633655220270157\n",
      "Epoch 9 Loss 0.010821344330906868\n",
      "Epoch 9 Loss 0.0062599992379546165\n",
      "Epoch 9 Loss 0.005381365306675434\n",
      "Validation accuracy is 0.9865205883979797\n",
      "Test acc. 0.9860132932662964\n",
      "Start training for  task1_cnn_g17y2_wnd_26_online_False_size_81876\n",
      "Epoch 0 Loss 1.2360328435897827\n",
      "Epoch 0 Loss 0.08260811120271683\n",
      "Epoch 0 Loss 0.09884674847126007\n",
      "Epoch 0 Loss 0.02290213108062744\n",
      "Epoch 0 Loss 0.05005650222301483\n",
      "Epoch 0 Loss 0.0006615867023356259\n",
      "Epoch 0 Loss 0.017475232481956482\n",
      "Epoch 0 Loss 0.020255956798791885\n",
      "Epoch 0 Loss 0.027061378583312035\n",
      "Epoch 0 Loss 0.020578136667609215\n",
      "Epoch 0 Loss 0.03023204393684864\n",
      "Epoch 0 Loss 0.030356448143720627\n",
      "Epoch 0 Loss 0.00576768396422267\n",
      "Validation accuracy is 0.9891577959060669\n",
      "Epoch 1 Loss 0.007716884836554527\n",
      "Epoch 1 Loss 0.03893383592367172\n",
      "Epoch 1 Loss 0.004814689513295889\n",
      "Epoch 1 Loss 0.004368391819298267\n",
      "Epoch 1 Loss 0.011767657473683357\n",
      "Epoch 1 Loss 0.0025330521166324615\n",
      "Epoch 1 Loss 0.04809676110744476\n",
      "Epoch 1 Loss 0.003225763328373432\n",
      "Epoch 1 Loss 0.014445153065025806\n",
      "Epoch 1 Loss 0.00472572585567832\n",
      "Epoch 1 Loss 0.056780241429805756\n",
      "Epoch 1 Loss 0.0018190313130617142\n",
      "Epoch 1 Loss 0.0012538888258859515\n",
      "Validation accuracy is 0.9925556182861328\n",
      "Epoch 2 Loss 0.0018643861403688788\n",
      "Epoch 2 Loss 0.028471706435084343\n",
      "Epoch 2 Loss 0.07146436721086502\n",
      "Epoch 2 Loss 0.004894624929875135\n",
      "Epoch 2 Loss 0.0003792972129303962\n",
      "Epoch 2 Loss 0.0009374383953399956\n",
      "Epoch 2 Loss 0.015160007402300835\n",
      "Epoch 2 Loss 0.018546102568507195\n",
      "Epoch 2 Loss 0.0015400818083435297\n",
      "Epoch 2 Loss 0.0019746299367398024\n",
      "Epoch 2 Loss 0.0033319732174277306\n",
      "Epoch 2 Loss 0.0002312829892616719\n",
      "Epoch 2 Loss 0.025628315284848213\n",
      "Validation accuracy is 0.9908721446990967\n",
      "Epoch 3 Loss 0.07902418076992035\n",
      "Epoch 3 Loss 0.021634012460708618\n",
      "Epoch 3 Loss 0.009112266823649406\n",
      "Epoch 3 Loss 0.008949206210672855\n",
      "Epoch 3 Loss 0.0018020301358774304\n",
      "Epoch 3 Loss 0.0006573101272806525\n",
      "Epoch 3 Loss 0.0032790580298751593\n",
      "Epoch 3 Loss 0.001441139611415565\n",
      "Epoch 3 Loss 0.0029496841598302126\n",
      "Epoch 3 Loss 0.020613493397831917\n",
      "Epoch 3 Loss 0.039558447897434235\n",
      "Epoch 3 Loss 0.0714958906173706\n",
      "Epoch 3 Loss 0.00048616263666190207\n",
      "Validation accuracy is 0.9927873015403748\n",
      "Epoch 4 Loss 0.003056679852306843\n",
      "Epoch 4 Loss 0.001274796319194138\n",
      "Epoch 4 Loss 0.0022168541327118874\n",
      "Epoch 4 Loss 0.02645055204629898\n",
      "Epoch 4 Loss 0.00045481108827516437\n",
      "Epoch 4 Loss 0.012998277321457863\n",
      "Epoch 4 Loss 0.0001674367958912626\n",
      "Epoch 4 Loss 0.010623828507959843\n",
      "Epoch 4 Loss 0.0007185578579083085\n",
      "Epoch 4 Loss 0.005532220937311649\n",
      "Epoch 4 Loss 0.0003852057852782309\n",
      "Epoch 4 Loss 0.03430212661623955\n",
      "Epoch 4 Loss 0.0005941130220890045\n",
      "Validation accuracy is 0.9938684701919556\n",
      "Epoch 5 Loss 0.04389706626534462\n",
      "Epoch 5 Loss 0.0007522489177063107\n",
      "Epoch 5 Loss 0.00016754321404732764\n",
      "Epoch 5 Loss 0.001166252070106566\n",
      "Epoch 5 Loss 0.0005484902649186552\n",
      "Epoch 5 Loss 0.02914586290717125\n",
      "Epoch 5 Loss 0.0005383956013247371\n",
      "Epoch 5 Loss 0.0004444234073162079\n",
      "Epoch 5 Loss 0.000486383301904425\n",
      "Epoch 5 Loss 0.0022509314585477114\n",
      "Epoch 5 Loss 0.0003947915101889521\n",
      "Epoch 5 Loss 0.0003784400469157845\n",
      "Epoch 5 Loss 0.0007949535502120852\n",
      "Validation accuracy is 0.9930652976036072\n",
      "Epoch 6 Loss 0.04230935871601105\n",
      "Epoch 6 Loss 0.022229479625821114\n",
      "Epoch 6 Loss 0.0009485518094152212\n",
      "Epoch 6 Loss 0.010277535766363144\n",
      "Epoch 6 Loss 0.034917332231998444\n",
      "Epoch 6 Loss 0.0015782912960276008\n",
      "Epoch 6 Loss 0.009213184006512165\n",
      "Epoch 6 Loss 0.0001573520275996998\n",
      "Epoch 6 Loss 0.00101596605964005\n",
      "Epoch 6 Loss 0.0001541789824841544\n",
      "Epoch 6 Loss 0.006412251386791468\n",
      "Epoch 6 Loss 0.00016785979096312076\n",
      "Epoch 6 Loss 0.02226012386381626\n",
      "Validation accuracy is 0.9933278560638428\n",
      "Epoch 7 Loss 0.003227286972105503\n",
      "Epoch 7 Loss 2.4485216272296384e-05\n",
      "Epoch 7 Loss 0.0003109949757345021\n",
      "Epoch 7 Loss 7.066539637889946e-06\n",
      "Epoch 7 Loss 0.00036432480555959046\n",
      "Epoch 7 Loss 0.0003989982942584902\n",
      "Epoch 7 Loss 0.0001523733080830425\n",
      "Epoch 7 Loss 0.00011512495257193223\n",
      "Epoch 7 Loss 0.000639398000203073\n",
      "Epoch 7 Loss 0.007725008297711611\n",
      "Epoch 7 Loss 0.001134703867137432\n",
      "Epoch 7 Loss 0.0018626467790454626\n",
      "Epoch 7 Loss 0.0017861509695649147\n",
      "Validation accuracy is 0.9910266399383545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss 0.00023228072677738965\n",
      "Epoch 8 Loss 0.0008259005844593048\n",
      "Epoch 8 Loss 0.004255452658981085\n",
      "Epoch 8 Loss 0.0024846363812685013\n",
      "Epoch 8 Loss 7.87401368143037e-05\n",
      "Epoch 8 Loss 0.00017070554895326495\n",
      "Epoch 8 Loss 0.00035071666934527457\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fd81ab48b011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_tasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mmake_plots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexecution_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Local\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mtask1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_plots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-fd81ab48b011>\u001b[0m in \u001b[0;36mtask1\u001b[0;34m(plot)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start training for \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                     \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0;31m#print(\"Start training for \", rnn_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/ownCloud/Studies/Master/ETH-Z端rich/Neural-Systems/Project/PartC/NeuralSystems/classifiers.py\u001b[0m in \u001b[0;36mtrain_CNN\u001b[0;34m(datasets, model_name, feature_extraction, normalize_input, online)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m                 \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/ownCloud/Studies/Master/ETH-Z端rich/Neural-Systems/Project/PartC/NeuralSystems/classifiers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1204\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def task1(plot=True):\n",
    "    \"\"\"\n",
    "    For each bird, for offline and online variants of the task, and for each of the above window sizes, \n",
    "    please train a network that will predict segmentation on the 10% test set of that bird. Please store \n",
    "    the optimal hyperparameters (including optimal gap size), optimizer choices, loss functions, and \n",
    "    trained network parameters (using pytorch-checkpoint, or a well-documented equivalent method).\n",
    "    \"\"\"\n",
    "    ## Set a few parameters\n",
    "    # This corresponds to 28ms, 64ms, 104ms\n",
    "    wnd_sizes = [7,16,26]\n",
    "    bird_names = [\"g17y2\", \"g19o10\", \"g4p5\", \"R3428\"]\n",
    "    online_mode = [False, True]\n",
    "    \n",
    "    # Some data parameters\n",
    "    test_frac = 0.1       # Fraction of spectograms in the test_set\n",
    "    if execution_mode == \"Local\":\n",
    "        limit = 100           # Amount of windows to extract for training, validation and test set\n",
    "        dt = 50\n",
    "    else:\n",
    "        limit = 80000\n",
    "        dt = 3\n",
    "    on_fracs=0.5          # Fraction of windows which should have 'vocal' target\n",
    "                   # Stride\n",
    "    \n",
    "    # Some RNN parameters\n",
    "    network_type = \"gru\"  # Choose from {'rnn', 'lstm', 'gru'}\n",
    "    num_layers = 1        # Number of layers of the rnn. 1 should be ok.\n",
    "    hidden_size = 100     # Size of the hidden input of the rnn\n",
    "    \n",
    "    # A dictionary where all the MSEs of the different neural networks will be stored\n",
    "    results = {}\n",
    "    \n",
    "    # Check if the results of these experiments have already been computed\n",
    "    parameter_hash = hash_object([wnd_sizes, bird_names, online_mode, test_frac, limit, on_fracs, dt, network_type, num_layers, hidden_size])\n",
    "    result_path = PREDICTIONS_PATH + f\"task1_results_hash_{parameter_hash}\"\n",
    "    \n",
    "    if path.isfile(result_path):\n",
    "        results = load(result_path)\n",
    "    else:\n",
    "        # Train the models for all specified birds, window sizes and online modes\n",
    "        # First iterate over all birds\n",
    "        for bird_name in bird_names:\n",
    "            # Run garbage collection to free unused memory\n",
    "            gc.collect()\n",
    "            print(\"Working on bird: \", bird_name)\n",
    "\n",
    "            # The bird \"g4p5\" only contains one labelled spectogram so we can't really train a classifier for this\n",
    "            # TODO: Change implementation so that it's possible!\n",
    "            if bird_name == \"g4p5\":\n",
    "                continue\n",
    "\n",
    "            results[bird_name] = {}\n",
    "\n",
    "            # First load the data of the current bird\n",
    "            bird_data = load_bird_data(names = bird_name)\n",
    "\n",
    "            # Extract the labelled data\n",
    "            bird_data, _ = extract_labelled_spectograms(bird_data)\n",
    "\n",
    "            # Split the spectograms of this bird into a train-, validation-, and test set\n",
    "            train_data, test_data = train_test_split({bird_name : bird_data[bird_name]}, configs = test_frac, seed = 42)\n",
    "            train_data, validation_data = train_test_split(train_data, configs = 0.2, seed = 42)\n",
    "\n",
    "            # After the bird data is ready, iterate over all window sizes and online modes\n",
    "            for wnd_size in wnd_sizes:\n",
    "                results[bird_name][wnd_size] = {}\n",
    "                for online in online_mode:\n",
    "                    results[bird_name][wnd_size][\"online\" if online else \"offline\"] = {}\n",
    "\n",
    "                    # Run garbage collection to free unused memory\n",
    "                    gc.collect()                \n",
    "\n",
    "                    # Extract windows for the training, validation and test set\n",
    "                    data = [train_data, validation_data, test_data]\n",
    "                    windows = []\n",
    "                    for dataset in data:\n",
    "                        windows.append(create_windows(\n",
    "                            bird_data=dataset,\n",
    "                            wnd_sizes=wnd_size,\n",
    "                            limits=limit,\n",
    "                            on_fracs=on_fracs,\n",
    "                            dt=dt,\n",
    "                            online = online,\n",
    "                            seed=42)[0])\n",
    "\n",
    "                    windows_train, windows_validation, windows_test = windows\n",
    "\n",
    "                    # Transform the dictionary into an array, which can be used to train our models\n",
    "                    X_train, y_train = flatten_windows_dic(windows_train[wnd_size])\n",
    "                    X_validation, y_validation = flatten_windows_dic(windows_validation[wnd_size])\n",
    "                    X_test, y_test = flatten_windows_dic(windows_test[wnd_size])\n",
    "\n",
    "                    # Prepare the final dataset\n",
    "                    dataset = {\n",
    "                        \"train\": (X_train, y_train),\n",
    "                        \"validation\": (X_validation, y_validation),\n",
    "                        \"test\": (X_test, y_test)\n",
    "                    }\n",
    "\n",
    "                    # Train a CNN and an RNN\n",
    "                    cnn_name = f\"task1_cnn_{bird_name}_wnd_{wnd_size}_online_{online}_size_{len(X_train)}\"\n",
    "                    rnn_name = f\"task1_rnn_{bird_name}_wnd_{wnd_size}_online_{online}_size_{len(X_train)}\"\n",
    "\n",
    "                    print(\"Start training for \", cnn_name)\n",
    "                    cnn = train_CNN(dataset,model_name = cnn_name, normalize_input=False, online=online)\n",
    "\n",
    "                    #print(\"Start training for \", rnn_name)\n",
    "                    #rnn = train_RNN(dataset,model_name=rnn_name, network_type=network_type, hidden_size=hidden_size, \n",
    "                    #                num_layers=num_layers, normalize_input=False, online=online)\n",
    "\n",
    "                    # Make predictions for the test set\n",
    "                    y_pred_cnn = cnn(X_test)\n",
    "                    #y_pred_rnn = rnn(X_test).cpu()\n",
    "\n",
    "                    def metrics(y_true, y_pred):\n",
    "                        y_pred = y_pred.cpu()\n",
    "                        # Compute error metrics\n",
    "                        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                            y_true,\n",
    "                            y_pred,\n",
    "                            average=\"binary\"\n",
    "                        )\n",
    "                        accuracy = accuracy_score(y_true, y_pred)\n",
    "                        return {\"accuracy\": accuracy, \n",
    "                                \"precision\": precision, \n",
    "                                \"recall\": recall, \n",
    "                                \"f1\":f1}\n",
    "\n",
    "                    results[bird_name][wnd_size][\"online\" if online else \"offline\"][\"cnn\"] = metrics(y_test, y_pred_cnn)\n",
    "                    #results[bird_name][wnd_size][\"online\" if online else \"offline\"][\"rnn\"] = metrics(y_test, y_pred_rnn)\n",
    "        \n",
    "        # Store the result to avoid recomputing everything the next time\n",
    "        dump(results, result_path)\n",
    "    \n",
    "    if not plot:\n",
    "        return\n",
    "    \n",
    "    # Plot the results\n",
    "    # TODO put bird \"g4p5\" back in!\n",
    "    for bird_name in bird_names:\n",
    "        if bird_name == \"g4p5\":\n",
    "            continue\n",
    "        \n",
    "        for online in online_mode:\n",
    "            for model in [\"cnn\"]: #, \"rnn\"]\n",
    "                for index, mode in enumerate([\"online\", \"offline\"]):\n",
    "                    scores = []\n",
    "                    accuracies = []\n",
    "                    precisions = []\n",
    "                    recalls = []\n",
    "                    \n",
    "                    for wnd_size in wnd_sizes:\n",
    "                        accuracies.append(results[bird_name][wnd_size][mode][model][\"accuracy\"])\n",
    "                        precisions.append(results[bird_name][wnd_size][mode][model][\"precision\"])\n",
    "                        recalls.append(results[bird_name][wnd_size][mode][model][\"recall\"])\n",
    "                    \n",
    "                    plt.figure(figsize=(9,6))\n",
    "                    plt.plot(wnd_sizes, accuracies, label = \"Accuracy\", marker='x')\n",
    "                    plt.plot(wnd_sizes, precisions, label = \"Precision\", marker='x')\n",
    "                    plt.plot(wnd_sizes, recalls, label = \"Recall\", marker='x')\n",
    "                    plt.grid(which=\"both\")\n",
    "                    plt.title(f\"Metrics of {model} on bird {bird_name} using {mode} mode\")\n",
    "                    plt.xlabel(\"Window size\")\n",
    "                    plt.ylabel(\"Metrics\")\n",
    "                    plt.legend()\n",
    "\n",
    "if run_tasks[\"task1\"]:\n",
    "    make_plots = True if execution_mode == \"Local\" else False\n",
    "    task1(plot = make_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def task3(plot = True):\n",
    "    \"\"\"\n",
    "    For birds g17y2 and R3428 separately, how much labelled data is needed to have good performance for \n",
    "    an entire data set? Characterize the tradeoff between amount of annotation data and improvement in \n",
    "    precision and recall of the binary label predictor.\n",
    "    \"\"\"\n",
    "    ## Set a few parameters\n",
    "    bird_names = [\"g17y2\", \"R3428\"]\n",
    "    wnd_size = 20\n",
    "    \n",
    "    # Some data parameters\n",
    "    test_frac = 0.2             # Fraction of spectograms in the test_set\n",
    "    if execution_mode == \"Local\":\n",
    "        limits = [100,200,300,500]  # Amount of windows to extract for training- and validation set combined \n",
    "        dt = 50\n",
    "    else:\n",
    "        limits = [100,1000,10000,100000]\n",
    "        dt = 3\n",
    "    on_fracs=0.5                # Fraction of windows which should have 'vocal' target\n",
    "    dt = 50                     # Stride\n",
    "    \n",
    "    # Some RNN parameters\n",
    "    network_type = \"gru\"  # Choose from {'rnn', 'lstm', 'gru'}\n",
    "    num_layers = 1        # Number of layers of the rnn. 1 should be ok.\n",
    "    hidden_size = 100     # Size of the hidden input of the rnn\n",
    "    \n",
    "    # A dictionary where all the MSEs of the different neural networks will be stored\n",
    "    results = {}\n",
    "    \n",
    "    # Check if the results of these experiments have already been computed\n",
    "    parameter_hash = hash_object([bird_names, wnd_size, test_frac, limits, on_fracs, dt, network_type, num_layers, hidden_size])\n",
    "    result_path = PREDICTIONS_PATH + f\"task3_results_hash_{parameter_hash}\"\n",
    "    \n",
    "    if path.isfile(result_path):\n",
    "        results = load(result_path)\n",
    "    else:\n",
    "        # Train the models for all specified birds, window sizes and online modes\n",
    "        # First iterate over all birds\n",
    "        for bird_name in bird_names:\n",
    "            print(\"Working on bird: \", bird_name)\n",
    "\n",
    "            results[bird_name] = {}\n",
    "\n",
    "            # First load the data of the current bird\n",
    "            bird_data = load_bird_data(names = bird_name)\n",
    "\n",
    "            # Extract the labelled data\n",
    "            bird_data, _ = extract_labelled_spectograms(bird_data)\n",
    "\n",
    "            # Split the spectograms of this bird into a train-, validation-, and test set\n",
    "            train_data, test_data = train_test_split({bird_name : bird_data[bird_name]}, configs = test_frac, seed = 42)\n",
    "            train_data, validation_data = train_test_split(train_data, configs = 0.2, seed = 42)\n",
    "\n",
    "            for limit in limits:\n",
    "                results[bird_name][limit] = {\"cnn\":{}, \"rnn\":{}}\n",
    "\n",
    "                # Run garbage collection to free unused memory\n",
    "                gc.collect()\n",
    "\n",
    "                data = [(train_data, int(limit * 0.9)), (validation_data,limit - int(limit * 0.9)), (test_data,limit)]\n",
    "\n",
    "                windows = []\n",
    "                for data_tuple in data:\n",
    "                    dataset, amount_of_windows = data_tuple\n",
    "                    windows.append(create_windows(\n",
    "                        bird_data=dataset,\n",
    "                        wnd_sizes=wnd_size,\n",
    "                        limits=amount_of_windows,\n",
    "                        on_fracs=on_fracs,\n",
    "                        dt=dt,\n",
    "                        online = False,\n",
    "                        seed=42)[0])\n",
    "\n",
    "                windows_train, windows_validation, windows_test = windows\n",
    "\n",
    "                # Transform the dictionary into an array, which can be used to train our models\n",
    "                X_train, y_train = flatten_windows_dic(windows_train[wnd_size])\n",
    "                X_validation, y_validation = flatten_windows_dic(windows_validation[wnd_size])\n",
    "                X_test, y_test = flatten_windows_dic(windows_test[wnd_size])\n",
    "\n",
    "                # Prepare the final dataset\n",
    "                dataset = {\n",
    "                    \"train\": (X_train, y_train),\n",
    "                    \"validation\": (X_validation, y_validation),\n",
    "                    \"test\": (X_test, y_test)\n",
    "                }\n",
    "\n",
    "                # Train a CNN and an RNN\n",
    "                cnn_name = f\"task3_cnn_{bird_name}_wnd_{wnd_size}_size_{len(X_train)}\"\n",
    "                rnn_name = f\"task3_rnn_{bird_name}_wnd_{wnd_size}_size_{len(X_train)}\"\n",
    "\n",
    "                print(\"Start training for \", cnn_name)\n",
    "                cnn = train_CNN(dataset,model_name = cnn_name, normalize_input=False)\n",
    "                cnn = wrap_cnn(cnn, mode=\"for_spectograms\", normalize_input=False)\n",
    "\n",
    "                #print(\"Start training for \", rnn_name)\n",
    "                #rnn = train_RNN(dataset,model_name=rnn_name, network_type=network_type, hidden_size=hidden_size, num_layers=num_layers, normalize_input=False)\n",
    "                #rnn = wrap_rnn(rnn, mode=\"for_spectograms\", normalize_input=False)\n",
    "\n",
    "                # Make predictions for the test set\n",
    "                summary_cnn = compare_classifiers(dataset=bird_data, model_dic={f\"cnn_bird_{bird_name}_windows_{limit}\": cnn}, print_summary=False)\n",
    "                #summary_rnn = compare_classifiers(dataset=bird_data, model_dic={f\"rnn_bird_{bird_name}_windows_{limit}\": rnn}, print_summary=False)\n",
    "\n",
    "                results[bird_name][limit][\"cnn\"] = {\n",
    "                    \"score\": np.mean(summary_cnn[bird_name][f\"cnn_bird_{bird_name}_windows_{limit}\"][\"score_mean\"]),\n",
    "                    \"accuracy\": summary_cnn[bird_name][f\"cnn_bird_{bird_name}_windows_{limit}\"][\"accuracy\"],\n",
    "                    \"precision\": summary_cnn[bird_name][f\"cnn_bird_{bird_name}_windows_{limit}\"][\"precision\"],\n",
    "                    \"recall\": summary_cnn[bird_name][f\"cnn_bird_{bird_name}_windows_{limit}\"][\"recall\"]\n",
    "                }\n",
    "                #results[bird_name][limit][\"rnn\"] = {\n",
    "                #    \"score\": np.mean(summary_rnn[bird_name][f\"rnn_bird_{bird_name}_windows_{limit}\"][\"score_mean\"]),\n",
    "                #    \"accuracy\": summary_rnn[bird_name][f\"rnn_bird_{bird_name}_windows_{limit}\"][\"accuracy\"],\n",
    "                #    \"precision\": summary_rnn[bird_name][f\"rnn_bird_{bird_name}_windows_{limit}\"][\"precision\"],\n",
    "                #    \"recall\": summary_rnn[bird_name][f\"rnn_bird_{bird_name}_windows_{limit}\"][\"recall\"]\n",
    "                #}\n",
    "        \n",
    "        # Store the result to avoid recomputing everything the next time\n",
    "        dump(results, result_path)\n",
    "    \n",
    "    if not plot:\n",
    "        return\n",
    "    \n",
    "    # Plot the results\n",
    "    # TODO: Fix CNN. when done, uncomment line 107\n",
    "    for bird_name in bird_names:\n",
    "        for model in [\"cnn\"]: #, \"rnn\"]\n",
    "            scores = []\n",
    "            accuracies = []\n",
    "            precisions = []\n",
    "            recalls = []\n",
    "            for limit in limits:\n",
    "                scores.append(results[bird_name][limit][model][\"score\"])\n",
    "                accuracies.append(results[bird_name][limit][model][\"accuracy\"])\n",
    "                precisions.append(results[bird_name][limit][model][\"precision\"])\n",
    "                recalls.append(results[bird_name][limit][model][\"recall\"])\n",
    "                \n",
    "            plt.figure(figsize=(9,6))\n",
    "            plt.plot(limits, scores, label = \"Score\", marker='x')\n",
    "            plt.plot(limits, accuracies, label = \"Accuracy\", marker='x')\n",
    "            plt.plot(limits, precisions, label = \"Precision\", marker='x')\n",
    "            plt.plot(limits, recalls, label = \"Recall\", marker='x')\n",
    "            plt.grid(which=\"both\")\n",
    "            plt.title(f\"Metrics of {model} on bird {bird_name}\")\n",
    "            plt.xlabel(\"Training set size\")\n",
    "            plt.ylabel(\"Metrics\")\n",
    "            plt.legend()\n",
    "\n",
    "if run_tasks[\"task3\"]:\n",
    "    make_plots = True if execution_mode == \"Local\" else False\n",
    "    task3(plot = make_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def task4(plot = True):\n",
    "    \"\"\"\n",
    "    Generalization across birds: How well does a segmentation network trained on a subset of the birds \n",
    "    perform on a left-out (out-of-distribution) bird?\n",
    "    \"\"\"\n",
    "    # Set some general parameters\n",
    "    use_feature_extraction = False\n",
    "    wnd_sz = 20\n",
    "    if execution_mode == \"Local\":\n",
    "        limit = 100#70000\n",
    "    else:\n",
    "        limit = 80000\n",
    "    standardize = False\n",
    "    online = False\n",
    "\n",
    "    # Some RNN parameters\n",
    "    network_type = \"gru\"    # Choose from {'rnn', 'lstm', 'gru'}\n",
    "    num_layers = 1\n",
    "    hidden_size = 100\n",
    "\n",
    "    # The paths to the models\n",
    "    #base = path.dirname(path.abspath(__file__))\n",
    "    base = os.getcwd()\n",
    "    cnn_name = \"task4_cnn_features_%s_wnd_sz_%s_limit_%s.model\" % (use_feature_extraction, wnd_sz, limit)\n",
    "    cnn_path = path.join(base, MODEL_PATH+cnn_name)\n",
    "    rnn_name = \"task4_rnn_type_%s_num_layers_%s_hidden_size_%s_features_%s_wnd_sz_%s_limit_%s.model\" % (\n",
    "        network_type, num_layers, hidden_size, use_feature_extraction, wnd_sz, limit)\n",
    "    rnn_path = path.join(base, MODEL_PATH+rnn_name)\n",
    "    \n",
    "    # Check if the results of these experiments have already been computed\n",
    "    parameter_hash = hash_object([use_feature_extraction, wnd_sz, limit, standardize, online, network_type, num_layers, hidden_size])\n",
    "    result_path = PREDICTIONS_PATH + f\"task4_results_hash_{parameter_hash}\"\n",
    "    \n",
    "    if path.isfile(result_path):\n",
    "        #(summary_cnn, summary_rnn) = load(result_path)\n",
    "        (summary_cnn) = load(result_path)\n",
    "    else:\n",
    "\n",
    "        if not (path.isfile(cnn_path)):# and path.isfile(rnn_path)):\n",
    "            # Load the data and get all labelled spectograms\n",
    "            bird_data = load_bird_data(names=[\"g17y2\"])\n",
    "\n",
    "            if standardize:\n",
    "                bird_data = standardize_data(bird_data, coarse_mode=\"per_spectogram\", fine_mode=\"scalar\")\n",
    "            data_labelled, _ = extract_labelled_spectograms(bird_data)\n",
    "\n",
    "            # Perform a train-validation-test split\n",
    "            data_train, data_test = train_test_split(bird_data=data_labelled, configs=0.33, seed=42)\n",
    "            data_val, data_test = train_test_split(bird_data=data_test, configs=0.5, seed=42)\n",
    "\n",
    "            # Extract the windows from the spectograms\n",
    "            windows_train, _ = create_windows(bird_data=data_train, wnd_sizes=wnd_sz, limits=limit, on_fracs=0.5, dt=5, seed=42)\n",
    "            windows_val, _ = create_windows(bird_data=data_val, wnd_sizes=wnd_sz, limits=int(limit/2), on_fracs=0.5, dt=5, seed=42)\n",
    "            windows_test, _ = create_windows(bird_data=data_test, wnd_sizes=wnd_sz, limits=int(limit/2), on_fracs=0.5, dt=5, seed=42)\n",
    "\n",
    "            X_train, y_train = flatten_windows_dic(windows_train[wnd_sz])\n",
    "            X_val, y_val = flatten_windows_dic(windows_val[wnd_sz])\n",
    "            X_test, y_test = flatten_windows_dic(windows_test[wnd_sz])\n",
    "\n",
    "            dataset = {\n",
    "                \"train\": (X_train, y_train),\n",
    "                \"validation\": (X_val, y_val),\n",
    "                \"test\": (X_test, y_test)\n",
    "            }\n",
    "\n",
    "            if not path.isfile(cnn_path):\n",
    "                cnn = train_CNN(dataset, cnn_name, normalize_input=True, online=online)\n",
    "            #if not path.isfile(rnn_path):\n",
    "            #    rnn = train_RNN(dataset, rnn_name, network_type=network_type, hidden_size=hidden_size,\n",
    "            #                    num_layers=num_layers, normalize_input=True, online=online)\n",
    "\n",
    "        # Load the CNN\n",
    "        cnn = load_cnn(cnn_path, wnd_sz, online=online)\n",
    "        #rnn = load_rnn(rnn_path, network_type, nfreq=128, hidden_size=hidden_size, num_layers=num_layers, device=DEVICE)\n",
    "\n",
    "        # Print the number of parameters\n",
    "        print(\"CNN has \", sum(p.numel() for p in cnn.parameters()), \" parameters.\")\n",
    "        # print(\"RNN has \", sum(p.numel() for p in rnn.parameters()), \" parameters.\")\n",
    "\n",
    "        cnn_wrapped = wrap_cnn(cnn, mode=\"for_spectograms\")\n",
    "        # rnn_wrapped = wrap_rnn(rnn, mode=\"for_spectograms\")\n",
    "        #compare_classifiers(dataset=None, model_dic={\"cnn\": cnn_wrapped, \"rnn\": rnn_wrapped}, print_summary=True)\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        transfer_model_dic_cnn = get_transfer_learning_models_CNN(\n",
    "            bird_names=[\"g19o10\", \"R3428\"],\n",
    "            base_model=cnn,\n",
    "            arch=\"task4_cnn_\",\n",
    "            wnd_sz=wnd_sz,\n",
    "            limit=limit,\n",
    "            retrain_layers=4,\n",
    "            standardize_input=standardize)\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        #transfer_model_dic_rnn = get_transfer_learning_models_RNN(\n",
    "        #    bird_names=[\"g19o10\", \"R3428\"],\n",
    "        #    base_model=rnn,\n",
    "        #    arch=\"task4_rnn_\",\n",
    "        #    wnd_sz=wnd_sz,\n",
    "        #    limit=limit,\n",
    "        #    network_type=network_type,  # Choose from [\"rnn\",\"lstm\",\"gru\"]\n",
    "        #    hidden_size=hidden_size,\n",
    "        #    num_layers=num_layers,\n",
    "        #    retrain_layers=4,\n",
    "        #    nfreq=128,\n",
    "        #    standardize_input=standardize\n",
    "        #)\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        transfer_model_dic_cnn[\"base_CNN\"] = cnn\n",
    "        #transfer_model_dic_rnn[\"base_RNN\"] = rnn\n",
    "\n",
    "        for key in transfer_model_dic_cnn:\n",
    "            transfer_model_dic_cnn[key] = wrap_cnn(transfer_model_dic_cnn[key], mode=\"for_spectograms\", normalize_input=True)\n",
    "\n",
    "        #for key in transfer_model_dic_rnn:\n",
    "        #    transfer_model_dic_rnn[key] = wrap_rnn(transfer_model_dic_rnn[key], mode=\"for_spectograms\", normalize_input=True)\n",
    "\n",
    "        summary_cnn = compare_classifiers(dataset=None, model_dic=transfer_model_dic_cnn, print_summary=True)\n",
    "        #summary_rnn = compare_classifiers(dataset=None, model_dic=transfer_model_dic_rnn, print_summary=True)\n",
    "    \n",
    "        # Store the result to avoid recomputing everything the next time\n",
    "        #dump((summary_cnn, summary_rnn), result_path)\n",
    "        dump((summary_cnn), result_path)\n",
    "        \n",
    "    if not plot:\n",
    "        return\n",
    "    \n",
    "    ################################################################################\n",
    "    # Plotting starts here\n",
    "    ################################################################################\n",
    "    # Some plot parameters\n",
    "    width = 0.2\n",
    "    metric_names = [\"Score\",\"Accuracy\", \"Precision\", \"Recall\"]\n",
    "    x = np.arange(len(BIRD_NAMES)) # Amount of different bars to plot\n",
    "\n",
    "    summaries = [summary_cnn] #, summary_rnn]\n",
    "    for index, model in enumerate([\"CNN\"]):#, \"RNN\"]):\n",
    "        ## First plot a summary of the base models over the different birds\n",
    "        summary = summaries[index]\n",
    "        scores = []\n",
    "        accuracies = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "\n",
    "        # Extract the different metrics\n",
    "        for bird_name in BIRD_NAMES:\n",
    "            scores.append(summary[bird_name]['base_'+model][\"score_mean\"])\n",
    "            accuracies.append(summary[bird_name]['base_'+model][\"accuracy\"])\n",
    "            precisions.append(summary[bird_name]['base_'+model][\"precision\"])\n",
    "            recalls.append(summary[bird_name]['base_'+model][\"recall\"])\n",
    "\n",
    "        metrics = [scores, accuracies, precisions, recalls]\n",
    "\n",
    "        # Make the first plots showing how the base models performed over all birds\n",
    "        plt.figure(figsize=(9,6))\n",
    "        for i in range(len(metrics)):\n",
    "            plt.bar(x + i * width, metrics[i], width, label = metric_names[i])\n",
    "        plt.grid(which=\"both\")\n",
    "        plt.title(f\"Generalization of {model} trained on {BIRD_NAMES[0]}\")\n",
    "        plt.xticks(x + 1.5 * width, BIRD_NAMES)\n",
    "        plt.xlabel(\"Bird\")\n",
    "        plt.ylabel(\"Metrics\")\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        # Now generate the second type of plots showing how transfer learning improved the situation\n",
    "        x = np.array([0,1.5,3,4.5])\n",
    "        x2 = np.array([0,0.75,1.5,3,3.75,4.5])\n",
    "        scores = []\n",
    "        accuracies = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        for bird_name in [\"g19o10\", \"R3428\"]:\n",
    "            scores.append(summary[bird_name]['base_'+model][\"score_mean\"])\n",
    "            scores.append(summary[bird_name]['task4_'+model.lower()+\"_\"+bird_name][\"score_mean\"])\n",
    "            accuracies.append(summary[bird_name]['base_'+model][\"accuracy\"])\n",
    "            accuracies.append(summary[bird_name]['task4_'+model.lower()+\"_\"+bird_name][\"accuracy\"])\n",
    "            precisions.append(summary[bird_name]['base_'+model][\"precision\"])\n",
    "            precisions.append(summary[bird_name]['task4_'+model.lower()+\"_\"+bird_name][\"precision\"])\n",
    "            recalls.append(summary[bird_name]['base_'+model][\"recall\"])\n",
    "            recalls.append(summary[bird_name]['task4_'+model.lower()+\"_\"+bird_name][\"recall\"])\n",
    "\n",
    "        metrics = [scores, accuracies, precisions, recalls]\n",
    "\n",
    "        # Make the first plots showing how the base models performed over all birds\n",
    "        plt.figure(figsize=(12,6))\n",
    "        for i in range(len(metrics)):\n",
    "            plt.bar(x + i * width, metrics[i], width, label = metric_names[i])\n",
    "        plt.grid(which=\"both\")\n",
    "        plt.title(f\"Transfer-learning of {model}\")\n",
    "        plt.xticks(x2 + 1.5 * width,[f\"Base {model}\", \"\\ng19o10\", f\"{model}_g19o10\", f\"Base {model}\", \"\\nR3428\", f\"{model}_R3428\"])\n",
    "        plt.xlabel(\"Bird\")\n",
    "        plt.ylabel(\"Metrics\")\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "if run_tasks[\"task4\"]:\n",
    "    make_plots = True if execution_mode == \"Local\" else False\n",
    "    task4(plot = make_plots)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PartC_AutoSyllClust.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
